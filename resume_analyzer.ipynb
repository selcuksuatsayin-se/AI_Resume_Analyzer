{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The text from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\sayin\\documents\\ai_resume_analyzer\\.venv\\lib\\site-packages (0.11.4)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\sayin\\documents\\ai_resume_analyzer\\.venv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\sayin\\documents\\ai_resume_analyzer\\.venv\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\sayin\\documents\\ai_resume_analyzer\\.venv\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\sayin\\documents\\ai_resume_analyzer\\.venv\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\sayin\\documents\\ai_resume_analyzer\\.venv\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\sayin\\documents\\ai_resume_analyzer\\.venv\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\sayin\\documents\\ai_resume_analyzer\\.venv\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (45.0.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\sayin\\documents\\ai_resume_analyzer\\.venv\\lib\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\sayin\\documents\\ai_resume_analyzer\\.venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sayin\\documents\\ai_resume_analyzer\\.venv\\lib\\site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber pytesseract pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        # Try direct text extraction\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "\n",
    "        if text.strip():\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Direct text extraction failed: {e}\")\n",
    "\n",
    "    # Fallback to OCR for image-based PDFs\n",
    "    print(\"Falling back to OCR for image-based PDF.\")\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path)\n",
    "        for image in images:\n",
    "            page_text = pytesseract.image_to_string(image)\n",
    "            text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"OCR failed: {e}\")\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Text from PDF:\n",
      "SUJOY DUTTA\n",
      "West Bengal, India | P: +xxxxxxxxxx | xxxxxxxxxxxxxx@gmail.com | https://www.linkedin.com/in/dutta-sujoy/\n",
      "3rd-year Computer Science student at KIIT with expertise in Machine Learning and Deep Learning, and\n",
      "practical experience in developing predictive models and recommendation systems. Focused on leveraging\n",
      "technology to address real-world challenges, currently engaged in a Generative AI project for predictive\n",
      "maintenance in manufacturing.\n",
      "EDUCATION\n",
      "KALINGA INSTITUTE OF INDUSTRIAL TECHNOLOGY Bhubaneswar, Odisha\n",
      "Bachelor in Computer Science and Engineering Expected July 2026\n",
      "Cumulative GPA: 8.48 / 10.0\n",
      "Relevant Coursework: Data Structures; Databases; Operating Systems; Algorithms; Object-oriented\n",
      "programming;\n",
      "PROJECTS\n",
      "Movie Recommendation System\n",
      "Developed a content-based recommendation system using a similarity matrix to enhance movie\n",
      "suggestions based on user preferences.\n",
      "Integrated the TMDB API to fetch and display detailed information and posters for over 10,000 movies.\n",
      "Implemented efficient similarity calculations to ensure accurate recommendations.\n",
      "Technologies Used: Python, Scikit-Learn, Streamlit, TMDB API\n",
      "GitHub Repo: https://github.com/dutta-sujoy/Movie-Recommendation-System\n",
      "House Price Prediction Model\n",
      "Developed a Random Forest model that achieved an accuracy of 85% in predicting house prices.\n",
      "Processed and analyzed data from 13,000+ housing records to enhance model performance.\n",
      "Designed a Streamlit application that reduced user input time by 50% and provided instant price\n",
      "predictions.\n",
      "Implemented feature engineering techniques that improved model precision by 15%.\n",
      "Technologies Used: Python, Scikit-Learn, Streamlit.\n",
      "GitHub Repo: https://github.com/dutta-sujoy/Bengaluru-House-Price-Prediction\n",
      "TECHNICAL SKILLS\n",
      "Programming Languages: Python, Java, C++\n",
      "Machine Learning: Scikit-Learn, TensorFlow, Keras, Supervised and Unsupervised Learning, GANs\n",
      "Generative Model\n",
      "Data Analysis: Pandas, NumPy, Matplotlib, Seaborn\n",
      "Database Management: SQL\n",
      "ACTIVITIES\n",
      "GeeksforGeeks KIIT Chapter February 2024 - Present\n",
      "( Core Developer )\n",
      "Collaborate with team members to build projects and develop technical solutions.\n",
      "AISoC February 2023 - Present\n",
      "( Core Member )\n",
      "Assisted in organizing workshops, coding events, and seminars for the student community.\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"Resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(\"\\nExtracted Text from PDF:\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Google GenerativeAI Api Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google.generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What is the capital of Turkey?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Ankara\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.06339950114488602\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 7,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 9\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-flash\"\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankara\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_resume(resume_text, job_description=None):\n",
    "    if not resume_text:\n",
    "        return {\"error\": \"Resume text is required for analysis.\"}\n",
    "    \n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    \n",
    "    base_prompt = f\"\"\"\n",
    "    You are an experienced HR with Technical Experience in the field of any one job role from Data Science, Data Analyst, DevOPS, Machine Learning Engineer, Prompt Engineer, AI Engineer, Full Stack Web Development, Big Data Engineering, Marketing Analyst, Human Resource Manager, Software Developer your task is to review the provided resume.\n",
    "    Please share your professional evaluation on whether the candidate's profile aligns with the role.ALso mention Skills he already have and siggest some skills to imorve his resume , alos suggest some course he might take to improve the skills.Highlight the strengths and weaknesses.\n",
    "\n",
    "    Resume:\n",
    "    {resume_text}\n",
    "    \"\"\"\n",
    "\n",
    "    if job_description:\n",
    "        base_prompt += f\"\"\"\n",
    "        Additionally, compare this resume to the following job description:\n",
    "        \n",
    "        Job Description:\n",
    "        {job_description}\n",
    "        \n",
    "        Highlight the strengths and weaknesses of the applicant in relation to the specified job requirements.\n",
    "        \"\"\"\n",
    "\n",
    "    response = model.generate_content(base_prompt)\n",
    "\n",
    "    analysis = response.text.strip()\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resume_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(analyze_resume(\u001b[43mresume_text\u001b[49m))\n",
      "\u001b[31mNameError\u001b[39m: name 'resume_text' is not defined"
     ]
    }
   ],
   "source": [
    "print(analyze_resume(resume_text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
